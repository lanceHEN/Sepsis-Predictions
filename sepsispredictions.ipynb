{
 "cells": [
  {
   "cell_type": "code",
   "id": "2975c072-d966-49de-92b9-dbae8ab576c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:07:20.763962Z",
     "start_time": "2024-12-18T01:07:20.245471Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "328bfdb6-8154-44ef-a4de-9e317d303dc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:07:22.031042Z",
     "start_time": "2024-12-18T01:07:21.847595Z"
    }
   },
   "source": "sepsis = np.genfromtxt('sepsis.csv', delimiter=',', skip_header=1)",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1ee4b474-8462-48c1-a6a7-67b003ec203a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:20:41.268319Z",
     "start_time": "2024-12-17T23:20:41.260503Z"
    }
   },
   "source": [
    "# initialize data\n",
    "X = sepsis[:,:2]\n",
    "y = sepsis[:,3]\n",
    "y = np.reshape(y,(110204,1))\n",
    "# get rid of rows containing missing values\n",
    "y = y[~np.isnan(X).any(axis=1)]\n",
    "X = X[~np.isnan(X).any(axis=1)]\n",
    "#print(y)"
   ],
   "outputs": [],
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "id": "62b9117b-b21d-4ec0-8eec-c50d2d1be508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:20:44.482701Z",
     "start_time": "2024-12-17T23:20:44.461812Z"
    }
   },
   "source": [
    "# split into train, test\n",
    "[X_train, X_test, y_train, y_test] = train_test_split(X, y, test_size = 0.2)\n",
    "X_train = scale(X_train)\n",
    "X_test = scale(X_test)\n"
   ],
   "outputs": [],
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "id": "c136fe9e-5895-4b2c-ad1f-e2775e3fc5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:20:46.681502Z",
     "start_time": "2024-12-17T23:20:46.678917Z"
    }
   },
   "source": [
    "def σ(φ, w):\n",
    "    '''\n",
    "    Computes the sigmoid activation function, which maps input values to the range (0, 1), representing their probability of success.\n",
    "    \n",
    "    :param φ: numpy array\n",
    "        Input data vector used in the computation. \n",
    "    :param w: numpy array\n",
    "        Weight vector applied to the input φ. These weights scale the input φ to produce different probabilities.\n",
    "    :return: float\n",
    "        The probability result of the sigmoid activation function, between 0 and 1.\n",
    "    '''\n",
    "    return 1/(1 + np.exp((-φ.T.dot(w)).item()))"
   ],
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:20:47.699570Z",
     "start_time": "2024-12-17T23:20:47.694937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_cross_entropy(Φ, y, w):\n",
    "    '''\n",
    "    Computes the binary cross-entropy loss for a logistic regression model.\n",
    "\n",
    "    :param Φ: numpy array of shape (n, d)\n",
    "        Input feature matrix, where `n` is the number of data points and `d` is the number of features.\n",
    "        Each row `Φ[i]` represents the features for the i-th data point.\n",
    "    :param y: numpy array of shape (n,1)\n",
    "        True binary labels for the data points, where each `y[i]` is either 0 or 1.\n",
    "    :param w: numpy array of shape (d, 1)\n",
    "        Weight vector used in the model, where `d` is the number of features.\n",
    "    :return: float\n",
    "        The average binary cross-entropy loss over all data points.\n",
    "    '''\n",
    "    sum = 0\n",
    "    n = Φ.shape[0]\n",
    "    d = Φ.shape[1]\n",
    "    for i in range(n):\n",
    "        φ = np.reshape(Φ[i], (d,1))\n",
    "        y_i = y[i]\n",
    "        u = φ.T.dot(w)\n",
    "        sum += (np.log(np.exp(u) + 1) - y_i * u)\n",
    "\n",
    "    return (1/n) * sum"
   ],
   "id": "bc2b2c8992cb5ffc",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:20:50.350876Z",
     "start_time": "2024-12-17T23:20:50.346959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_cross_entropy_grad(Φ, y, w):\n",
    "    '''\n",
    "    Computes the gradient of the binary cross entropy loss function with respect to the weight vector `w`.\n",
    "\n",
    "    :param Φ: numpy array of shape (n, d)\n",
    "        Input feature matrix, where `n` is the number of data points and `d` is the number of features.\n",
    "        Each row `Φ[i]` represents a single data point.\n",
    "    :param y: numpy array of shape (n,1)\n",
    "        True labels for each data point, where each `y[i]` is either 0 or 1.\n",
    "    :param w: numpy array of shape (d, 1)\n",
    "        Weight vector used for the logistic regression model.\n",
    "    :return: numpy array of shape (d, 1)\n",
    "        The gradient of the logistic loss function with respect to `w`.\n",
    "    '''\n",
    "    sum = 0\n",
    "    n = Φ.shape[0]\n",
    "    d = Φ.shape[1]\n",
    "    for i in range(n):\n",
    "        φ = np.reshape(Φ[i], (d,1))\n",
    "        y_i = y[i]\n",
    "        sum += (σ(φ, w) - y_i) * φ\n",
    "\n",
    "    return (1/n) * sum"
   ],
   "id": "47bd67d84006bece",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:20:52.164475Z",
     "start_time": "2024-12-17T23:20:52.161372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_cross_entropy_grad_l1(Φ, y, w, λ):\n",
    "    '''\n",
    "    Computes the gradient of the binary cross entropy loss function with L1 regularization.\n",
    "\n",
    "    :param Φ: numpy array of shape (n, d)\n",
    "        Input feature matrix, where `n` is the number of data points and `d` is the number of features.\n",
    "    :param y: numpy array of shape (n,1)\n",
    "        True labels for each data point, where each `y[i]` is either 0 or 1.\n",
    "    :param w: numpy array of shape (d, 1)\n",
    "        Weight vector used for the logistic regression model.\n",
    "    :param λ: float\n",
    "        Regularization strength (penalty term). Controls the influence of L1 regularization.\n",
    "    :return: numpy array of shape (d, 1)\n",
    "        The gradient of the logistic loss function with L1 regularization with respect to `w`.\n",
    "    '''\n",
    "    return binary_cross_entropy_grad(Φ, y, w) + λ * np.sign(w)"
   ],
   "id": "ab2312dc7f6fdc34",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:20:54.035152Z",
     "start_time": "2024-12-17T23:20:54.030146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize feature maps (just use linear with bias term for simplicity)\n",
    "Φ_train = np.hstack((X_train, np.ones((X_train.shape[0],1))))\n",
    "Φ_test = np.hstack((X_test, np.ones((X_test.shape[0],1))))"
   ],
   "id": "7adb3505ee911e0a",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:20:55.035861Z",
     "start_time": "2024-12-17T23:20:55.032064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gd(Φ, y, w, λ, η, iterations):\n",
    "    '''\n",
    "    Performs gradient descent optimization with L1-regularized binary cross-entropy loss.\n",
    "\n",
    "    :param Φ: numpy array of shape (n, d)\n",
    "        Input feature matrix, where `n` is the number of data points and `d` is the number of features.\n",
    "        Each row `Φ[i]` corresponds to the features of one data point.\n",
    "    :param y: numpy array of shape (n,1)\n",
    "        True binary labels (0 or 1) for each data point.\n",
    "    :param w: numpy array of shape (d, 1)\n",
    "        Initial weight vector for the logistic regression model.\n",
    "    :param λ: float\n",
    "        Regularization strength (penalty term) for L1 regularization.\n",
    "    :param η: float\n",
    "        Learning rate, which controls the step size for weight updates.\n",
    "    :param iterations: int\n",
    "        Number of iterations to run the gradient descent optimization.\n",
    "    :return: numpy array of shape (d, 1)\n",
    "        Optimized weight vector after performing gradient descent.\n",
    "    '''\n",
    "    for i in range(iterations):\n",
    "        u = binary_cross_entropy_grad_l1(Φ, y, w, λ)\n",
    "        w = w - η * u\n",
    "    return w"
   ],
   "id": "6c86c5c9cb98c6c5",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:06:09.618992Z",
     "start_time": "2024-12-17T23:21:00.176189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finally train on real sepsis data\n",
    "w = np.zeros((Φ_train.shape[1],1))\n",
    "w = gd(Φ_train, y_train, w, λ=0.001, η=0.001, iterations=10000)"
   ],
   "id": "e4f1f2606a5a4d75",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:10:27.229262Z",
     "start_time": "2024-12-18T00:10:27.223668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_predict(Φ, w):\n",
    "    '''\n",
    "    Computes binary predictions for a batch of data points using the sigmoid function.\n",
    "\n",
    "    This function applies the sigmoid function to the dot product of input features and weights \n",
    "    for all data points in the batch. The resulting probabilities are rounded to 0 or 1, \n",
    "    producing binary predictions suitable for binary classification tasks.\n",
    "\n",
    "    :param Φ: numpy array of shape (n, d)\n",
    "        Input feature matrix, where `n` is the number of data points and `d` is the number of features.\n",
    "        Each row `Φ[i]` corresponds to the features of one data point.\n",
    "    :param w: numpy array of shape (d, 1)\n",
    "        Weight vector used for prediction.\n",
    "    :return: numpy array of shape (n, 1)\n",
    "        Binary predictions (0 or 1) for each data point.\n",
    "    '''\n",
    "    yhats = []\n",
    "    n = Φ.shape[0]\n",
    "    d = Φ.shape[1]\n",
    "    for i in range(n):\n",
    "        φ = np.reshape(Φ[i], (d,1))\n",
    "        yhats.append(np.round(σ(φ, w)))\n",
    "        \n",
    "    yhats = np.array(yhats)\n",
    "    yhats = np.reshape(yhats,(n,1))\n",
    "    return yhats\n"
   ],
   "id": "3755e24032aa3b58",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:10:29.978870Z",
     "start_time": "2024-12-18T00:10:29.868906Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Accuracy score on test data:\", accuracy_score(batch_predict(Φ_test, w), y_test))",
   "id": "66e4ed7442040a37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test data: 0.9245497028265505\n"
     ]
    }
   ],
   "execution_count": 168
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
